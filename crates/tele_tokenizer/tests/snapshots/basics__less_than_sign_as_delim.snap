---
source: crates/tele_tokenizer/tests/basics.rs
assertion_line: 129
expression: tokenizer.tokenize()

---
Ok(
    [
        Token {
            token_type: WhiteSpace,
            start_pos: Pos {
                offset: 0,
                line: 1,
                column: 1,
            },
            end_pos: Pos {
                offset: 1,
                line: 1,
                column: 2,
            },
            content: " ",
        },
        Token {
            token_type: Delim,
            start_pos: Pos {
                offset: 1,
                line: 1,
                column: 2,
            },
            end_pos: Pos {
                offset: 2,
                line: 1,
                column: 3,
            },
            content: "<",
        },
        Token {
            token_type: WhiteSpace,
            start_pos: Pos {
                offset: 2,
                line: 1,
                column: 3,
            },
            end_pos: Pos {
                offset: 3,
                line: 1,
                column: 4,
            },
            content: " ",
        },
        Token {
            token_type: EOF,
            start_pos: Pos {
                offset: 3,
                line: 1,
                column: 4,
            },
            end_pos: Pos {
                offset: 3,
                line: 1,
                column: 4,
            },
            content: "",
        },
    ],
)
